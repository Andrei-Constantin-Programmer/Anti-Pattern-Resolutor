{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b669f3",
   "metadata": {},
   "source": [
    "# Java Antipattern Scanner - Refactored Demo\n",
    "\n",
    "This is a refactored Java antipattern scanner demonstration, based on a modular codebase structure.\n",
    "\n",
    "## Key improvements:\n",
    "\n",
    "- **Modular structure**: Clear separation of agents, workflow, and data layers\n",
    "- **English documentation**: All comments and docstrings translated to English\n",
    "- **Enhanced workflow**: Multi-step analysis pipeline with LLM integration\n",
    "- **Better error handling**: Comprehensive exception handling and fallbacks\n",
    "- **Standardized configuration**: Centralized settings management\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "This demo will create the following modular structure:\n",
    "\n",
    "```\n",
    "java_antipatterns_scanner/\n",
    "├── __init__.py                    # Package initialization\n",
    "├── config.py                      # Configuration management\n",
    "├── requirements.txt               # Dependency management\n",
    "├── main.py                        # Main entry script\n",
    "├── db/                           # Database module\n",
    "│   ├── __init__.py\n",
    "│   └── vector_db.py              # Vector database management\n",
    "├── analysis/                     # Analysis module\n",
    "│   ├── __init__.py\n",
    "│   ├── retriever.py             # Retrieval tools\n",
    "│   └── analyzer.py              # Code analyzer\n",
    "└── workflow/                     # Workflow module\n",
    "    ├── __init__.py\n",
    "    └── langgraph_workflow.py     # LangGraph workflow\n",
    "```\n",
    "\n",
    "## Limitations (To be addressed in future versions)\n",
    "\n",
    "- Query methods: Still using the original code snippets for semantic querying\n",
    "- Agent structure: Current version is still a single-agent architecture\n",
    "- Model support: Only local Ollama model is supported\n",
    "- Usage: Manual code provision for analysis is still required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步：创建项目目录结构\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 定义项目根目录\n",
    "project_root = Path(\"java_antipatterns_scanner\")\n",
    "\n",
    "# 创建目录结构\n",
    "directories = [\n",
    "    project_root,\n",
    "    project_root / \"db\",\n",
    "    project_root / \"analysis\", \n",
    "    project_root / \"workflow\"\n",
    "]\n",
    "\n",
    "print(\"🚀 创建项目目录结构...\")\n",
    "for directory in directories:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ 创建目录: {directory}\")\n",
    "\n",
    "# 创建__init__.py文件\n",
    "init_files = [\n",
    "    project_root / \"__init__.py\",\n",
    "    project_root / \"db\" / \"__init__.py\",\n",
    "    project_root / \"analysis\" / \"__init__.py\",\n",
    "    project_root / \"workflow\" / \"__init__.py\"\n",
    "]\n",
    "\n",
    "for init_file in init_files:\n",
    "    init_file.touch()\n",
    "    print(f\"✅ 创建文件: {init_file}\")\n",
    "\n",
    "print(\"\\n📁 项目结构创建完成!\")\n",
    "print(\"\\n目录结构:\")\n",
    "def print_tree(directory, prefix=\"\", is_last=True):\n",
    "    \"\"\"递归打印目录树\"\"\"\n",
    "    name = directory.name\n",
    "    print(f\"{prefix}{'└── ' if is_last else '├── '}{name}/\")\n",
    "    \n",
    "    # 获取子项目并排序\n",
    "    children = sorted([child for child in directory.iterdir() if child.is_dir()])\n",
    "    files = sorted([child for child in directory.iterdir() if child.is_file()])\n",
    "    \n",
    "    # 打印子目录\n",
    "    for i, child in enumerate(children):\n",
    "        is_last_child = (i == len(children) - 1) and len(files) == 0\n",
    "        new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "        print_tree(child, new_prefix, is_last_child)\n",
    "    \n",
    "    # 打印文件\n",
    "    for i, file in enumerate(files):\n",
    "        is_last_file = i == len(files) - 1\n",
    "        print(f\"{prefix}{'└── ' if is_last else '├── '}{'└── ' if is_last_file else '├── '}{file.name}\")\n",
    "\n",
    "print_tree(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407489f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二步：创建配置管理模块\n",
    "config_content = '''\"\"\"\n",
    "配置管理模块 - 统一管理项目配置参数\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    \"\"\"项目配置类\"\"\"\n",
    "    \n",
    "    # 基础路径配置\n",
    "    PROJECT_ROOT = Path(__file__).parent\n",
    "    DATA_DIR = PROJECT_ROOT.parent / \"static\"\n",
    "    \n",
    "    # LLM模型配置\n",
    "    LLM_MODEL = \"granite3.3:8b\"\n",
    "    EMBEDDING_MODEL = \"nomic-embed-text:v1.5\"\n",
    "    \n",
    "    # 向量数据库配置\n",
    "    VECTOR_DB_PATH = os.path.expanduser(\"~/antipattern_vectordb\")\n",
    "    ANTIPATTERN_FILE = DATA_DIR / \"ap.txt\"\n",
    "    \n",
    "    # 文档分割配置\n",
    "    CHUNK_SIZE = 1000\n",
    "    CHUNK_OVERLAP = 200\n",
    "    \n",
    "    # 检索配置\n",
    "    RETRIEVAL_K = 4  # 检索相关文档数量\n",
    "    \n",
    "    @classmethod\n",
    "    def get_antipattern_file_path(cls):\n",
    "        \"\"\"获取反模式文件路径，支持多种可能位置\"\"\"\n",
    "        possible_paths = [\n",
    "            cls.ANTIPATTERN_FILE,\n",
    "            cls.PROJECT_ROOT.parent / \"static\" / \"ap.txt\",\n",
    "            Path(\"static/ap.txt\"),\n",
    "            Path(\"ap.txt\")\n",
    "        ]\n",
    "        \n",
    "        for path in possible_paths:\n",
    "            if path.exists():\n",
    "                return str(path)\n",
    "        \n",
    "        # 如果都不存在，返回默认路径（用于错误提示）\n",
    "        return str(cls.ANTIPATTERN_FILE)\n",
    "\n",
    "# 全局配置实例\n",
    "config = Config()\n",
    "'''\n",
    "\n",
    "# 写入配置文件\n",
    "config_file = project_root / \"config.py\"\n",
    "with open(config_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"✅ 配置管理模块 (config.py) 创建完成\")\n",
    "\n",
    "# 创建requirements.txt\n",
    "requirements_content = '''# LangChain相关\n",
    "langchain>=0.1.0\n",
    "langchain-community>=0.0.20\n",
    "langchain-ollama>=0.1.0\n",
    "langgraph>=0.0.30\n",
    "\n",
    "# 向量数据库\n",
    "chromadb>=0.4.0\n",
    "\n",
    "# 其他依赖\n",
    "typing-extensions>=4.0.0\n",
    "'''\n",
    "\n",
    "requirements_file = project_root / \"requirements.txt\"\n",
    "with open(requirements_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"✅ 依赖配置文件 (requirements.txt) 创建完成\")\n",
    "print(\"\\n📋 配置要点:\")\n",
    "print(\"- 支持多种反模式文件位置自动检测\")\n",
    "print(\"- 统一的模型和路径参数管理\")  \n",
    "print(\"- 可通过环境变量覆盖配置\")\n",
    "print(\"- 模块化的配置结构\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三步：实现向量数据库模块\n",
    "vector_db_content = '''\"\"\"\n",
    "向量数据库管理模块 - 负责文档加载、分割和向量化存储\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "try:\n",
    "    from langchain_community.document_loaders import TextLoader\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    from langchain_ollama import OllamaEmbeddings\n",
    "except ImportError:\n",
    "    # 向后兼容导入\n",
    "    from langchain.document_loaders import TextLoader\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain.vectorstores import Chroma\n",
    "    from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "from .config import config\n",
    "\n",
    "\n",
    "class VectorDBManager:\n",
    "    \"\"\"向量数据库管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory: Optional[str] = None):\n",
    "        self.persist_directory = persist_directory or config.VECTOR_DB_PATH\n",
    "        self.vectordb = None\n",
    "        self.is_initialized = False\n",
    "    \n",
    "    def init_vector_db(self, file_path: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        初始化向量数据库\n",
    "        \n",
    "        Args:\n",
    "            file_path: 反模式文件路径，如果为None则使用配置中的路径\n",
    "            \n",
    "        Returns:\n",
    "            bool: 初始化是否成功\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 确定文件路径\n",
    "            if file_path is None:\n",
    "                file_path = config.get_antipattern_file_path()\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"❌ 文件不存在: {file_path}\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"📁 加载反模式文件: {file_path}\")\n",
    "            \n",
    "            # 加载文档\n",
    "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # 分割文档\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=config.CHUNK_SIZE,\n",
    "                chunk_overlap=config.CHUNK_OVERLAP,\n",
    "                length_function=len\n",
    "            )\n",
    "            split_docs = text_splitter.split_documents(docs)\n",
    "            print(f\"📄 文档分割为 {len(split_docs)} 个块\")\n",
    "            \n",
    "            # 创建持久化目录\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            \n",
    "            # 初始化嵌入模型\n",
    "            print(f\"🤖 初始化嵌入模型: {config.EMBEDDING_MODEL}\")\n",
    "            embedding = OllamaEmbeddings(model=config.EMBEDDING_MODEL)\n",
    "            \n",
    "            # 创建向量数据库\n",
    "            self.vectordb = Chroma(\n",
    "                embedding_function=embedding,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "            \n",
    "            # 添加文档\n",
    "            print(\"💾 添加文档到向量数据库...\")\n",
    "            self.vectordb.add_documents(split_docs)\n",
    "            \n",
    "            # 持久化\n",
    "            if hasattr(self.vectordb, 'persist'):\n",
    "                self.vectordb.persist()\n",
    "            \n",
    "            self.is_initialized = True\n",
    "            chunk_count = self.get_chunk_count()\n",
    "            print(f\"✅ 向量数据库初始化成功! 存储了 {chunk_count} 个文档块\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 向量数据库初始化失败: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_existing_db(self) -> bool:\n",
    "        \"\"\"加载已存在的向量数据库\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.persist_directory):\n",
    "                print(f\"⚠️ 向量数据库目录不存在: {self.persist_directory}\")\n",
    "                return False\n",
    "            \n",
    "            # 初始化嵌入模型\n",
    "            embedding = OllamaEmbeddings(model=config.EMBEDDING_MODEL)\n",
    "            \n",
    "            # 加载现有数据库\n",
    "            self.vectordb = Chroma(\n",
    "                embedding_function=embedding,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "            \n",
    "            chunk_count = self.get_chunk_count()\n",
    "            if chunk_count > 0:\n",
    "                self.is_initialized = True\n",
    "                print(f\"✅ 成功加载现有向量数据库，包含 {chunk_count} 个文档块\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"⚠️ 向量数据库为空\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 加载向量数据库失败: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_retriever(self):\n",
    "        \"\"\"获取检索器\"\"\"\n",
    "        if not self.is_initialized or self.vectordb is None:\n",
    "            raise ValueError(\"向量数据库未初始化，请先调用 init_vector_db() 或 load_existing_db()\")\n",
    "        \n",
    "        return self.vectordb.as_retriever(search_kwargs={\"k\": config.RETRIEVAL_K})\n",
    "    \n",
    "    def get_chunk_count(self) -> int:\n",
    "        \"\"\"获取文档块数量\"\"\"\n",
    "        try:\n",
    "            if self.vectordb and hasattr(self.vectordb, '_collection'):\n",
    "                return self.vectordb._collection.count()\n",
    "            return 0\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def init_vector_db(file_path: Optional[str] = None, force_recreate: bool = False) -> VectorDBManager:\n",
    "    \"\"\"\n",
    "    便捷函数：初始化向量数据库\n",
    "    \n",
    "    Args:\n",
    "        file_path: 反模式文件路径\n",
    "        force_recreate: 是否强制重新创建\n",
    "        \n",
    "    Returns:\n",
    "        VectorDBManager: 数据库管理器实例\n",
    "    \"\"\"\n",
    "    db_manager = VectorDBManager()\n",
    "    \n",
    "    # 如果不强制重新创建，先尝试加载现有数据库\n",
    "    if not force_recreate and db_manager.load_existing_db():\n",
    "        return db_manager\n",
    "    \n",
    "    # 创建新的数据库\n",
    "    if db_manager.init_vector_db(file_path):\n",
    "        return db_manager\n",
    "    else:\n",
    "        raise RuntimeError(\"向量数据库初始化失败\")\n",
    "'''\n",
    "\n",
    "# 写入向量数据库模块\n",
    "vector_db_file = project_root / \"db\" / \"vector_db.py\"\n",
    "with open(vector_db_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(vector_db_content)\n",
    "\n",
    "print(\"✅ 向量数据库模块 (db/vector_db.py) 创建完成\")\n",
    "\n",
    "# 更新db包的__init__.py\n",
    "db_init_content = '''\"\"\"\n",
    "数据库模块 - 向量数据库管理\n",
    "\"\"\"\n",
    "\n",
    "from .vector_db import VectorDBManager, init_vector_db\n",
    "\n",
    "__all__ = [\"VectorDBManager\", \"init_vector_db\"]\n",
    "'''\n",
    "\n",
    "db_init_file = project_root / \"db\" / \"__init__.py\"\n",
    "with open(db_init_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(db_init_content)\n",
    "\n",
    "print(\"✅ 数据库包初始化文件更新完成\")\n",
    "print(\"\\n📋 向量数据库模块特点:\")\n",
    "print(\"- 支持自动检测反模式文件位置\")\n",
    "print(\"- 可重用现有向量数据库\")\n",
    "print(\"- 统一的错误处理和日志输出\")\n",
    "print(\"- 灵活的配置参数支持\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四步：实现检索与分析模块\n",
    "\n",
    "# 创建retriever.py - 检索工具模块\n",
    "retriever_content = '''\"\"\"\n",
    "检索工具模块 - 封装检索相关功能\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    from langchain.tools.retriever import create_retriever_tool\n",
    "    from langchain_community.chat_models import ChatOllama\n",
    "except ImportError:\n",
    "    from langchain.tools.retriever import create_retriever_tool\n",
    "    from langchain.chat_models import ChatOllama\n",
    "\n",
    "from .config import config\n",
    "\n",
    "\n",
    "class RetrieverManager:\n",
    "    \"\"\"检索管理器\"\"\"\n",
    "    \n",
    "    def __init__(self, vectordb_manager):\n",
    "        self.vectordb_manager = vectordb_manager\n",
    "        self.retriever_tool = None\n",
    "        self.llm = None\n",
    "        self._initialize_components()\n",
    "    \n",
    "    def _initialize_components(self):\n",
    "        \"\"\"初始化检索组件\"\"\"\n",
    "        # 创建检索器\n",
    "        retriever = self.vectordb_manager.get_retriever()\n",
    "        \n",
    "        # 创建检索工具\n",
    "        self.retriever_tool = create_retriever_tool(\n",
    "            retriever,\n",
    "            name=\"retrieve_Java_antipatterns\",\n",
    "            description=\"Search for Java anti-patterns in the codebase\",\n",
    "        )\n",
    "        \n",
    "        # 初始化LLM\n",
    "        self.llm = ChatOllama(model=config.LLM_MODEL)\n",
    "        print(f\"🤖 LLM模型初始化: {self.llm.model}\")\n",
    "    \n",
    "    def get_retriever_tool(self):\n",
    "        \"\"\"获取检索工具\"\"\"\n",
    "        return self.retriever_tool\n",
    "    \n",
    "    def get_llm(self):\n",
    "        \"\"\"获取LLM实例\"\"\"\n",
    "        return self.llm\n",
    "\n",
    "\n",
    "def create_retriever_components(vectordb_manager):\n",
    "    \"\"\"\n",
    "    便捷函数：创建检索组件\n",
    "    \n",
    "    Args:\n",
    "        vectordb_manager: 向量数据库管理器\n",
    "        \n",
    "    Returns:\n",
    "        RetrieverManager: 检索管理器实例\n",
    "    \"\"\"\n",
    "    return RetrieverManager(vectordb_manager)\n",
    "'''\n",
    "\n",
    "retriever_file = project_root / \"analysis\" / \"retriever.py\"\n",
    "with open(retriever_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(retriever_content)\n",
    "\n",
    "print(\"✅ 检索模块 (analysis/retriever.py) 创建完成\")\n",
    "\n",
    "# 创建analyzer.py - 代码分析模块  \n",
    "analyzer_content = '''\"\"\"\n",
    "代码分析模块 - 实现Java代码反模式分析逻辑\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "class JavaCodeAnalyzer:\n",
    "    \"\"\"Java代码分析器\"\"\"\n",
    "    \n",
    "    # 分析提示模板 (与原Demo相同)\n",
    "    ANALYSIS_PROMPT = (\n",
    "        \"You are a senior Java code reviewer with deep experience in detecting software design antipatterns. \"\n",
    "        \"Below is the code to analyze:\\\\n\"\n",
    "        \"{code}\\\\n\\\\n\"\n",
    "        \"Here is additional context from the codebase:\\\\n\"\n",
    "        \"{context}\\\\n\\\\n\"\n",
    "        \"Your task is to:\\\\n\"\n",
    "        \"- Carefully analyze the code.\\\\n\"\n",
    "        \"- Identify any Java antipatterns or design smells present.\\\\n\"\n",
    "        \"- For each antipattern you find, include:\\\\n\"\n",
    "        \"  - [Name of the antipattern] (e.g., God Object, Long Method)\\\\n\"\n",
    "        \"  - [File or class/method name involved] (if detectable)\\\\n\"\n",
    "        \"  - [Brief description] of the issue\\\\n\"\n",
    "        \"  - [Why it\\\\'s a problem]\\\\n\"\n",
    "        \"  - [Suggested refactor]\\\\n\"\n",
    "        \"Be thorough but concise. If no antipatterns are found, say so.\"\n",
    "    )\n",
    "    \n",
    "    def __init__(self, retriever_manager):\n",
    "        self.retriever_manager = retriever_manager\n",
    "        self.retriever_tool = retriever_manager.get_retriever_tool()\n",
    "        self.llm = retriever_manager.get_llm()\n",
    "    \n",
    "    def retrieve_context(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        检索相关上下文信息\n",
    "        \n",
    "        Args:\n",
    "            code: Java代码\n",
    "            \n",
    "        Returns:\n",
    "            str: 检索到的上下文信息\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"🔍 检索相关反模式上下文...\")\n",
    "            \n",
    "            # 基于代码片段创建搜索查询\n",
    "            search_query = f\"Java antipatterns code analysis: {code[:200]}\"\n",
    "            \n",
    "            # 使用检索工具获取相关上下文\n",
    "            context = self.retriever_tool.invoke({\"query\": search_query})\n",
    "            \n",
    "            print(\"   ✅ 成功检索到相关上下文\")\n",
    "            return context\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 上下文检索错误: {e}\")\n",
    "            return \"No additional context available due to retrieval error.\"\n",
    "    \n",
    "    def analyze_code(self, code: str, context: str = None) -> str:\n",
    "        \"\"\"\n",
    "        分析Java代码中的反模式\n",
    "        \n",
    "        Args:\n",
    "            code: 待分析的Java代码\n",
    "            context: 可选的上下文信息\n",
    "            \n",
    "        Returns:\n",
    "            str: 分析结果\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"🔍 分析代码中的反模式...\")\n",
    "            \n",
    "            # 如果没有提供上下文，则自动检索\n",
    "            if context is None:\n",
    "                context = self.retrieve_context(code)\n",
    "            \n",
    "            # 格式化分析提示\n",
    "            prompt = self.ANALYSIS_PROMPT.format(\n",
    "                code=code,\n",
    "                context=context\n",
    "            )\n",
    "            \n",
    "            # 使用LLM进行分析\n",
    "            response = self.llm.invoke(prompt)\n",
    "            result = response.content if hasattr(response, 'content') else str(response)\n",
    "            \n",
    "            print(\"   ✅ 代码分析完成\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"代码分析过程中发生错误: {e}\"\n",
    "            print(f\"   ❌ {error_msg}\")\n",
    "            return error_msg\n",
    "    \n",
    "    def full_analysis(self, code: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        完整的代码分析流程\n",
    "        \n",
    "        Args:\n",
    "            code: 待分析的Java代码\n",
    "            \n",
    "        Returns:\n",
    "            Dict: 包含所有分析结果的字典\n",
    "        \"\"\"\n",
    "        print(\"🚀 开始完整的Java反模式分析...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # 检索上下文\n",
    "        context = self.retrieve_context(code)\n",
    "        \n",
    "        # 执行分析\n",
    "        analysis_result = self.analyze_code(code, context)\n",
    "        \n",
    "        # 返回结构化结果\n",
    "        result = {\n",
    "            \"code\": code,\n",
    "            \"context\": context,\n",
    "            \"analysis\": analysis_result,\n",
    "            \"success\": \"Error\" not in analysis_result\n",
    "        }\n",
    "        \n",
    "        print(\"🎉 分析完成!\")\n",
    "        return result\n",
    "\n",
    "\n",
    "def create_analyzer(retriever_manager):\n",
    "    \"\"\"\n",
    "    便捷函数：创建代码分析器\n",
    "    \n",
    "    Args:\n",
    "        retriever_manager: 检索管理器\n",
    "        \n",
    "    Returns:\n",
    "        JavaCodeAnalyzer: 代码分析器实例\n",
    "    \"\"\"\n",
    "    return JavaCodeAnalyzer(retriever_manager)\n",
    "'''\n",
    "\n",
    "analyzer_file = project_root / \"analysis\" / \"analyzer.py\"\n",
    "with open(analyzer_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(analyzer_content)\n",
    "\n",
    "print(\"✅ 分析模块 (analysis/analyzer.py) 创建完成\")\n",
    "\n",
    "# 更新analysis包的__init__.py\n",
    "analysis_init_content = '''\"\"\"\n",
    "分析模块 - 代码检索和反模式分析\n",
    "\"\"\"\n",
    "\n",
    "from .retriever import RetrieverManager, create_retriever_components\n",
    "from .analyzer import JavaCodeAnalyzer, create_analyzer\n",
    "\n",
    "__all__ = [\n",
    "    \"RetrieverManager\", \n",
    "    \"create_retriever_components\",\n",
    "    \"JavaCodeAnalyzer\", \n",
    "    \"create_analyzer\"\n",
    "]\n",
    "'''\n",
    "\n",
    "analysis_init_file = project_root / \"analysis\" / \"__init__.py\"\n",
    "with open(analysis_init_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(analysis_init_content)\n",
    "\n",
    "print(\"✅ 分析包初始化文件更新完成\")\n",
    "print(\"\\n📋 分析模块特点:\")\n",
    "print(\"- 分离检索和分析逻辑\")\n",
    "print(\"- 支持独立的上下文检索\")\n",
    "print(\"- 结构化的分析结果返回\")\n",
    "print(\"- 统一的错误处理机制\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
